{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Começando com Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O que é o [Apache Spark](https://spark.apache.org/)?\n",
    "\n",
    "O Apache Spark é uma engine open-source de computação para programação paralela e distribuída para processamento de grandes volumes de dados ou dados em tempo real.\n",
    "\n",
    "O Spark distrubui fluxos de trabalho de processamento de dados em *clusters*, com paralelismo e tolerancia a falhas. Diferente do *MapReduce* utilizado em ferramentas como Hadoop, o Spark processa e mantém os dados na memória para acessos subsequentes, sem precisar ler ou gravar dados no disco a cada iteração, o que resulta em velocidades de execução significativamente mais altas.\n",
    "\n",
    "O Spark oferece suporte via API para diversas linguagens de programaçao utilizada por Cientistas de Dados como: Python, R, Scala e Java."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando o Apache Spark com PySpark no Windows\n",
    "\n",
    "#### 1 - Instalar o Java\n",
    "\n",
    "Para utilizar o PySpark, precisamos que seja instalado o Java em uma versão 7 ou superior. Obtenha a versão mais recente clicando [aqui](https://www.java.com/pt-BR/download/). \n",
    "\n",
    "Verifique a versão do Java instalada em sua máquina com a linha de comando no *prompt*:\n",
    "\n",
    "```\n",
    "java -version\n",
    "```\n",
    "\n",
    "Em minha instalação, utilizei a versão 8 (\"1.8.0_441\")\n",
    "\n",
    "#### Instalar o Python\n",
    "\n",
    "Deve ser instalado uma versão do Python superior a 2.6. Vale ressaltar que em minha primeira tentativa de instalação, tive problemas com Spark DataFrame na a versão 3.13 do Python, soluciando fazendo o downgrade para a [versão 3.11.9 do Python](https://www.python.org/downloads/release/python-3119/). Para obter a versão mais recente clique [aqui](https://www.python.org/downloads/windows/). \n",
    "\n",
    "Verifique a versão do Python instalada em sua máquina com a linha de comando no *prompt*:\n",
    "\n",
    "```\n",
    "python --version\n",
    "```\n",
    "\n",
    "#### Instalar o Apache Spark \n",
    "\n",
    "Acesse [aqui](http://spark.apache.org/downloads.html) e selecione a versão mais estável. Nessa instalação utilizamos a versão do Spark **3.5.5** com o tipo de pacote **Pre-built for Apache Hadoop 3.3**. Ao clicar em download, você será redirecionado para uma página com o link para Download.\n",
    "\n",
    "O arquivo baixado deverá ter a extensão .tgz, podendo ser descompactado com WinRAR. \n",
    "\n",
    "Não é necessário executar um instalador do Apache Spark, basta descompactar os arquivos e mover para uma pasta a sua escolhe. Recomendo que mova para seu disco \"C:\"\n",
    "\n",
    "<font color=red>Certifique-se de que o caminho onde os arquivos do Spark foram armazenados não contenham espaços (ex.: **\"C:\\spark\\spark-3.5.5-bin-hadoop3\"**).</font>\n",
    "\n",
    "Para testar o funcionamento do Spark execute os comandos abaixo em seu *prompt* de comando. Esses comandos assumem que você extraiu os arquivos do Spark na pasta **\"C:\\spark\\\"**.\n",
    "\n",
    "```\n",
    "cd C:\\spark\\spark-3.5.5-bin-hadoop3\n",
    "```\n",
    "\n",
    "```\n",
    "bin\\pyspark\n",
    "```\n",
    "\n",
    "O comando acima inicia o *shell* do PySpark que permite trabalhar interativamente com o Spark.\n",
    "\n",
    "Para sair basta digitar `exit()` e logo depois presionar *Enter*. Para voltar ao *prompt* pressione *Enter* novamente.\n",
    "\n",
    "#### Instalar o findspark\n",
    "\n",
    "Em seu *prompt*, execute:\n",
    "\n",
    "```\n",
    "pip install findspark\n",
    "```\n",
    "\n",
    "#### Instalar o winutils\n",
    "\n",
    "O Spark não inclui o utilitário **winutils.exe**, recurso necessário para funcionamento no windows. Se não informarmos onde o Spark deve procurar este utilitário, veremos alguns erros no console e também não conseguiremos executar alguns utilitários.\n",
    "\n",
    "Faça o download acessando o [repositório](https://github.com/steveloughran/winutils) para a versão do Hadoop para a qual sua instalação do Spark foi feita. Em nosso exemplo foi utilizada a versão 3.0. Faça o *download* apenas do arquivo **winutils.exe**.\n",
    "\n",
    "Crie uma pasta **\"hadoop\\bin\"** dentro da pasta que contém os arquivos do Spark (em nosso exemplo **\"C:\\spark\\spark-3.5.5-bin-hadoop3\"**) e copie o arquivo **winutils.exe** para dentro desta pasta.\n",
    "\n",
    "Se estiver usando uma versão do Hadoop superior a **hadoop-3.0.0**, faça download e instale os binários acessando o [repositório](https://github.com/cdarlint/winutils).\n",
    "Escolha a pasta correspondente à versão do Hadoop usada pelo seu Spark\n",
    "Extraia os arquivos para uma pasta local. Sugestão: C:\\spark\\spark-3.5.5-bin-hadoop3\\hadoop\\bin\n",
    "\n",
    "#### Configuran as variaveis ambiente\n",
    "\n",
    "Crie variáveis de ambiente no seu Windows. \n",
    "\n",
    "- **SPARK_HOME**=**\"C:\\spark\\spark-3.5.5-bin-hadoop3\"**)\n",
    "- **HADOOP_HOME**=**C:\\spark\\spark-3.5.5-bin-hadoop3\\hadoop**\n",
    "- Adicione os binários do Hadoop ao PATH -> **PATH=%PATH%**; **C:\\spark\\spark-3.5.5-bin-hadoop3\\hadoop\\bin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o funcionamento\n",
    "\n",
    "Após realizar o procedimento de instalação do Apache Spark, execute as células a seguir para testar o funcionamento básico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://guilhermeguim:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x225d855b5d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando uma Session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Nome: string, Idade: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando um dataframe\n",
    "data = [(\"Hello\", \"25\"),(\"Word\", \"30\")]\n",
    "colNames = [\"Nome\", \"Idade\"]\n",
    "df = spark.createDataFrame(data,colNames)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| Nome|Idade|\n",
      "+-----+-----+\n",
      "|Hello|   25|\n",
      "| Word|   30|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exibindo o DataFrame\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
